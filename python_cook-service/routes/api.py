# routes/api.py
from fastapi import APIRouter, HTTPException
from models.models import SearchRequest, KeywordSearchRequest
from data.db import collection, embed_model
from unidecode import unidecode
from typing import List
import math
from data.indexing import sync_recipes_to_chroma

router = APIRouter()

@router.post("/search")
def search(req: SearchRequest):
    """
    T√¨m ki·∫øm theo danh s√°ch nguy√™n li·ªáu v·ªõi scoring th√¥ng minh:
    - KH√îNG d√πng vector search (kh√¥ng c·∫ßn semantic cho ingredient matching)
    - Filtering ch√≠nh x√°c: Ch·ªâ tr·∫£ v·ªÅ m√≥n c√≥ T·ªà L·ªÜ MATCH ‚â• 60%
    - ∆Øu ti√™n m√≥n √≠t nguy√™n li·ªáu (3/5 > 3/10)
    - S·∫Øp x·∫øp theo: Match ratio ‚Üí S·ªë nguy√™n li·ªáu kh·ªõp ‚Üí Popularity
    """
    try:
        if not req.ingredients:
            return {"query": "No ingredients provided", "hits": []}
        
        print(f"[Search Ingredients] User ingredients: {req.ingredients}")

        # Chu·∫©n h√≥a user ingredients
        user_ings = set(ing.strip().lower() for ing in req.ingredients)
        
        # L·∫•y T·∫§T C·∫¢ recipes t·ª´ ChromaDB (kh√¥ng d√πng vector search)
        results = collection.get(include=["metadatas"])

        hits = []
        if results and results.get("ids"):
            for i, rid in enumerate(results["ids"]):
                meta = results["metadatas"][i]
                
                # Parse ingredients v√† tags t·ª´ recipe
                hit_ings = set(ing.strip().lower() for ing in meta.get("ingredients", "").split(", ") if ing.strip())
                hit_tags = set(tag.strip().lower() for tag in meta.get("tags", "").split(", ") if tag.strip())
                user_tags = set(tag.strip().lower() for tag in req.tags)

                # === FILTERS ===
                # Tags filter
                tags_match = user_tags.issubset(hit_tags) if user_tags else True
                if not tags_match:
                    continue

                # Cuisine filter
                hit_cuisine = meta.get("cuisineLowercase", "")
                user_cuisine = req.cuisine.lower() if req.cuisine else None
                cuisine_match = not user_cuisine or hit_cuisine == user_cuisine
                if not cuisine_match:
                    continue

                # Category filter
                hit_category = meta.get("categoryLowercase", "")
                user_category = req.category.lower() if req.category else None
                category_match = not user_category or hit_category == user_category
                if not category_match:
                    continue

                # === INGREDIENT MATCHING ===
                matched_ings = user_ings.intersection(hit_ings)
                matched_count = len(matched_ings)
                total_ings = len(hit_ings)
                
                # T·ªà L·ªÜ MATCH: S·ªë nguy√™n li·ªáu user c√≥ / T·ªïng nguy√™n li·ªáu c·ªßa m√≥n
                match_ratio = matched_count / total_ings if total_ings > 0 else 0
                
                # USER COVERAGE: Bao nhi√™u % nguy√™n li·ªáu user ƒë∆∞·ª£c s·ª≠ d·ª•ng
                user_coverage = matched_count / len(user_ings) if user_ings else 0
                
                # === NG∆Ø·ª†NG L·ªåC ===
                # Rule 1: M√≥n PH·∫¢I match √≠t nh·∫•t 60% t·ªïng nguy√™n li·ªáu
                MIN_MATCH_RATIO = 0.6  # 60%
                if match_ratio < MIN_MATCH_RATIO:
                    print(f"[Search] ‚ùå Skip '{meta.get('name')}' - Match {matched_count}/{total_ings} = {match_ratio*100:.0f}% < {MIN_MATCH_RATIO*100:.0f}%")
                    continue
                
                # Rule 2: Ho·∫∑c m√≥n match √≠t nh·∫•t 80% nguy√™n li·ªáu user nh·∫≠p (cho ph√©p user nh·∫≠p th√™m 1-2 th·ª©)
                MIN_USER_COVERAGE = 0.8  # 80%
                if user_coverage < MIN_USER_COVERAGE and match_ratio < 0.8:
                    print(f"[Search] ‚ùå Skip '{meta.get('name')}' - User coverage {matched_count}/{len(user_ings)} = {user_coverage*100:.0f}% < {MIN_USER_COVERAGE*100:.0f}%")
                    continue
                
                print(f"[Search] ‚úÖ Match '{meta.get('name')}' - {matched_count}/{total_ings} ({match_ratio*100:.0f}%), user coverage: {user_coverage*100:.0f}%")

                # === SCORING ===
                # 1. Match ratio score (c√†ng cao c√†ng t·ªët)
                ratio_score = match_ratio * 1000
                
                # 2. Matched count score (c√†ng nhi·ªÅu c√†ng t·ªët)
                count_score = matched_count * 50
                
                # 3. Recipe size penalty (∆∞u ti√™n m√≥n √≠t nguy√™n li·ªáu h∆°n)
                # M√≥n 3/5 nguy√™n li·ªáu > M√≥n 3/10 nguy√™n li·ªáu
                size_penalty = -total_ings * 5
                
                # 4. User coverage bonus (s·ª≠ d·ª•ng h·∫øt nguy√™n li·ªáu user c√≥)
                coverage_bonus = user_coverage * 200
                
                # 5. Popularity score (rating th·∫•p ƒë·ªÉ kh√¥ng ·∫£nh h∆∞·ªüng nhi·ªÅu)
                rate = meta.get("rate", 0.0)
                num_rates = meta.get("numberOfRate", 0)
                popularity_score = (rate / 5.0) * math.log(1 + num_rates) * 30

                # === T·ªîNG H·ª¢P ===
                relevance_score = (
                    ratio_score +           # ∆Øu ti√™n cao nh·∫•t: T·ªâ l·ªá match
                    count_score +           # S·ªë l∆∞·ª£ng nguy√™n li·ªáu kh·ªõp
                    size_penalty +          # Penalty cho m√≥n nhi·ªÅu nguy√™n li·ªáu
                    coverage_bonus +        # Bonus cho s·ª≠ d·ª•ng h·∫øt nguy√™n li·ªáu user c√≥
                    popularity_score        # Popularity (th·∫•p)
                )

                ingredients_raw = meta.get("ingredients", "")
                ingredients_list = [ing.strip() for ing in ingredients_raw.split(",") if ing.strip()]

                hits.append({
                    "id": meta.get("id"),
                    "name": meta.get("name"),
                    "short": meta.get("short", ""),
                    "image": meta.get("image", ""),
                    "calories": meta.get("calories", 0),
                    "time": meta.get("time", ""),
                    "size": meta.get("size", ""),
                    "difficulty": meta.get("difficulty", ""),
                    "cuisine": meta.get("cuisine", ""),
                    "category": meta.get("category", ""),
                    "rate": rate,
                    "numberOfRate": num_rates,
                    "ingredients": ingredients_list,
                    "relevance_score": relevance_score,
                    "match_ratio": match_ratio,
                    "matched_count": matched_count,
                    "total_ingredients": total_ings,
                    "user_coverage": user_coverage
                })

        # Sort theo: 1. Match ratio, 2. Matched count, 3. Popularity
        hits = sorted(hits, key=lambda x: (x["match_ratio"], x["matched_count"], x["rate"]), reverse=True)[:req.top_k]
        
        print(f"[Search Ingredients] Found {len(hits)} results with match_ratio ‚â• {0.6*100:.0f}%")

        return {"query": f"Ingredients: {', '.join(req.ingredients)}", "hits": hits}
    except Exception as e:
        print(f"[Search] Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/search/search-by-keyword")
def search_by_keyword(req: KeywordSearchRequest):
    """
    üîç HYBRID SEARCH - K·∫øt h·ª£p Text Matching + Vector Search:
    
    1. **Vector Search (Semantic)**: T√¨m m√≥n ƒÉn c√≥ nghƒ©a t∆∞∆°ng t·ª±
       - "g√† chi√™n" ‚Üí "g√† r√°n", "g√† gi√≤n", "g√† KFC"
       - "ph·ªü b√≤" ‚Üí "ph·ªü t√°i", "ph·ªü n·∫°m", "b√∫n b√≤"
       - Tr·ªçng s·ªë cao (3.0) ƒë·ªÉ khai th√°c s·ª©c m·∫°nh AI
    
    2. **Text Matching (Lexical)**: ƒê·∫£m b·∫£o ƒë·ªô ch√≠nh x√°c
       - Exact match: Kh·ªõp 100% (ƒëi·ªÉm cao)
       - Phrase match: Chu·ªói t·ª´ li√™n ti·∫øp
       - Word match: T·ª´ng t·ª´ ri√™ng l·∫ª
       - Tr·ªçng s·ªë v·ª´a ph·∫£i (2.0)
    
    3. **Filtering**: Tags, Cuisine, Category
    
    ‚Üí K·∫øt qu·∫£: V·ª´a ch√≠nh x√°c (text) v·ª´a th√¥ng minh (vector)
    """
    try:
        # Chu·∫©n h√≥a query
        keywords = req.keywords.strip()
        if not keywords:
            return {"query": "", "hits": []}
        
        keywords_lower = keywords.lower()
        keywords_no_accent = unidecode(keywords_lower)
        keyword_list = [kw.strip() for kw in keywords_no_accent.split() if kw.strip()]
        
        if not keyword_list:
            return {"query": keywords, "hits": []}

        print(f"[Search Keyword] Query: '{keywords}' ‚Üí Normalized: {keyword_list}")

        # Heuristic: action words (e.g., 'x√†o') should appear in result names
        # Map query action tokens to allowed synonyms in names
        action_map = {
            "xao": {"xao", "chien", "ran"},
            "x√†o": {"xao", "chien", "ran"},
            "chien": {"chien", "ran"},
            "r√°n": {"ran", "chien"},
            "ran": {"ran", "chien"}
        }
        query_actions = {tok for tok in keyword_list if tok in action_map}

        # Build query text v·ªõi tr·ªçng s·ªë cao cho t√™n m√≥n
        q = f"{keywords}. M√≥n ƒÉn: {keywords}. T√¨m ki·∫øm: {keywords}"

        # Encode query th√†nh vector
        q_emb = embed_model.encode(q).tolist()

        # Query ChromaDB v·ªõi nhi·ªÅu k·∫øt qu·∫£ h∆°n ƒë·ªÉ c√≥ th·ªÉ re-rank
        results = collection.query(
            query_embeddings=[q_emb],
            n_results=min(req.top_k * 5, 100),  # L·∫•y nhi·ªÅu ƒë·ªÉ re-rank
            include=["metadatas", "distances"]
        )

        hits = []
        MIN_VECTOR_SCORE = 500  # TƒÉng ng∆∞·ª°ng: y√™u c·∫ßu t∆∞∆°ng ƒë·ªìng ng·ªØ nghƒ©a m·∫°nh h∆°n
        if results and results.get("ids"):
            for i, rid in enumerate(results["ids"][0]):
                meta = results["metadatas"][0][i]
                
                # L·∫•y c√°c text fields ƒë·ªÉ matching
                name = meta.get('name', '')
                name_lower = meta.get('nameLowercase', name.lower())
                name_no_accent = meta.get('nameNoAccent', unidecode(name_lower))
                short = meta.get('short', '').lower()
                short_no_accent = unidecode(short)
                
                # Ki·ªÉm tra filters tr∆∞·ªõc (nhanh h∆°n)
                # Tags filter
                hit_tags = set(tag.strip().lower() for tag in meta.get("tags", "").split(", ") if tag.strip())
                user_tags = set(tag.strip().lower() for tag in req.tags)
                tags_match = user_tags.issubset(hit_tags) if user_tags else True
                
                if not tags_match:
                    continue

                # Cuisine filter
                hit_cuisine = meta.get("cuisineLowercase", "")
                user_cuisine = req.cuisine.lower() if req.cuisine else None
                cuisine_match = not user_cuisine or hit_cuisine == user_cuisine
                
                if not cuisine_match:
                    continue

                # Category filter
                hit_category = meta.get("categoryLowercase", "")
                user_category = req.category.lower() if req.category else None
                category_match = not user_category or hit_category == user_category
                
                if not category_match:
                    continue

                # === VECTOR SEARCH - SEMANTIC SIMILARITY ===
                # ƒê√¢y l√† ph·∫ßn QUAN TR·ªåNG NH·∫§T - AI hi·ªÉu nghƒ©a c·ªßa query
                distance = results["distances"][0][i]
                # Chuy·ªÉn distance ‚Üí similarity score (distance c√†ng nh·ªè = c√†ng gi·ªëng)
                vector_score = 1000 / (1 + distance * 2) if distance >= 0 else 0
                
                print(f"[Vector] '{meta.get('name')}' - distance={distance:.3f}, vector_score={vector_score:.1f}")

                # === TEXT MATCHING - LEXICAL PRECISION ===
                # ƒê·∫£m b·∫£o ƒë·ªô ch√≠nh x√°c b·∫±ng text matching
                name = meta.get('name', '')
                name_lower = meta.get('nameLowercase', name.lower())
                name_no_accent = meta.get('nameNoAccent', unidecode(name_lower))
                short = meta.get('short', '').lower()
                short_no_accent = unidecode(short)
                
                # 1. EXACT MATCH - Kh·ªõp 100%
                exact_match_score = 0
                if keywords_no_accent == name_no_accent:
                    exact_match_score = 1000
                    print(f"[Text] ‚úÖ EXACT MATCH: '{name}'")
                elif keywords_lower == name_lower:
                    exact_match_score = 900
                
                # 2. PHRASE MATCH - Chu·ªói t·ª´ xu·∫•t hi·ªán li√™n ti·∫øp
                phrase_match_score = 0
                if len(keyword_list) >= 2:
                    query_phrase = " ".join(keyword_list)
                    if query_phrase in name_no_accent:
                        phrase_match_score = 500
                        print(f"[Text] ‚úÖ PHRASE MATCH in name: '{name}'")
                    elif query_phrase in short_no_accent:
                        phrase_match_score = 200
                
                # 3. WORD MATCH - T·ª´ng t·ª´ ri√™ng l·∫ª
                name_words = set(name_no_accent.split())
                matched_in_name = sum(1 for kw in keyword_list if kw in name_words)
                
                word_match_score = 0
                if matched_in_name > 0:
                    match_percentage = matched_in_name / len(keyword_list)
                    word_match_score = match_percentage * 300
                    print(f"[Text] Words matched: {matched_in_name}/{len(keyword_list)} in '{name}'")
                
                # TEXT MATCHING TOTAL
                text_match_score = exact_match_score + phrase_match_score + word_match_score
                
                # === POPULARITY SCORE ===
                rate = meta.get("rate", 0.0)
                num_rates = meta.get("numberOfRate", 0)
                popularity_score = (rate / 5.0) * math.log(1 + num_rates) * 50

                # === ACTION WORD HEURISTIC ===
                # If query contains an action word (e.g., 'xao'), ensure name includes a synonym
                action_required = len(query_actions) > 0
                action_ok = True
                if action_required:
                    action_ok = False
                    for act in query_actions:
                        synonyms = action_map.get(act, set())
                        if any(syn in name_no_accent for syn in synonyms) or any(syn in short_no_accent for syn in synonyms):
                            action_ok = True
                            break

                # === T·ªîNG H·ª¢P ƒêI·ªÇM (HYBRID APPROACH) ===
                # üéØ C√¥ng th·ª©c c√¢n b·∫±ng gi·ªØa Text v√† Vector
                # 
                # Vector (3.0): T√¨m m√≥n t∆∞∆°ng t·ª± v·ªÅ nghƒ©a - Cao nh·∫•t ƒë·ªÉ khai th√°c AI
                # Text (2.0): ƒê·∫£m b·∫£o ch√≠nh x√°c - Exact match ƒë∆∞·ª£c ∆∞u ti√™n
                # Popularity (0.5): Boost nh·∫π - M√≥n ngon, nhi·ªÅu ƒë√°nh gi√°
                
                relevance_score = (
                    text_match_score * 2.0 +       # Text matching
                    vector_score * 3.0 +           # üî• VECTOR SEARCH - Tr·ªçng s·ªë cao nh·∫•t
                    popularity_score * 0.5         # Popularity boost
                )
                
                # === RELEVANCE FILTERS ===
                # Y√™u c·∫ßu: ho·∫∑c text m·∫°nh, ho·∫∑c vector ƒë·ªß m·∫°nh
                short_query = len(keyword_list) <= 2
                name_match_pct = (matched_in_name / len(keyword_list)) if len(keyword_list) > 0 else 0.0
                required_pct = 1.0 if short_query else 0.6
                strong_text = (
                    exact_match_score > 0 or
                    phrase_match_score > 0 or
                    name_match_pct >= required_pct
                )

                if relevance_score <= 0:
                    continue
                # V·ªõi truy v·∫•n ng·∫Øn (‚â§2 t·ª´), y√™u c·∫ßu ƒë·ªß t·ª´ kh√≥a trong t√™n n·∫øu kh√¥ng c√≥ exact/phrase
                if short_query and not (exact_match_score > 0 or phrase_match_score > 0 or name_match_pct >= 1.0):
                    continue
                if not strong_text and vector_score < MIN_VECTOR_SCORE:
                    # Too weak semantically and lexically
                    continue
                if action_required and not action_ok:
                    # Query asked for an action (e.g., 'x√†o') but name doesn't reflect it
                    continue
                
                print(f"[Score] '{meta.get('name')}' ‚Üí Total={relevance_score:.1f} (text={text_match_score:.0f}, vector={vector_score:.1f})")

                # Build response
                ingredients_raw = meta.get("ingredients", "")
                ingredients_list = [ing.strip() for ing in ingredients_raw.split(",") if ing.strip()]
                
                hits.append({
                    "id": meta.get("id"),
                    "name": meta.get("name"),
                    "short": meta.get("short", ""),
                    "image": meta.get("image", ""),
                    "calories": meta.get("calories", 0),
                    "time": meta.get("time", ""),
                    "size": meta.get("size", ""),
                    "difficulty": meta.get("difficulty", ""),
                    "cuisine": meta.get("cuisine", ""),
                    "category": meta.get("category", ""),
                    "rate": rate,
                    "numberOfRate": num_rates,
                    "ingredients": ingredients_list,
                    "distance": distance,
                    "relevance_score": relevance_score,
                    "vector_score": vector_score,
                    "text_score": text_match_score
                })

        # Sort theo relevance_score gi·∫£m d·∫ßn v√† √°p d·ª•ng top_k
        hits = sorted(hits, key=lambda x: x["relevance_score"], reverse=True)[:req.top_k]
        
        print(f"[Search Keyword] Found {len(hits)} results")
        if hits:
            print(f"[Search Keyword] Top result: '{hits[0]['name']}' (total={hits[0]['relevance_score']:.1f}, vector={hits[0]['vector_score']:.1f}, text={hits[0]['text_score']:.1f})")

        return {"query": keywords, "hits": hits}
    except Exception as e:
        print(f"[Search] Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))
    
@router.post("/reindex")
async def reindex_data():
    sync_recipes_to_chroma()
    return {"message": "Reindex completed"}